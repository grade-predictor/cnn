{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "capstone-resnet50.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN6t/hn7HHdtsXBndKL/Wo5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyunkyungju/capstone-cnn/blob/main/capstone_resnet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JyTGlLXfNLii"
      },
      "outputs": [],
      "source": [
        "# torchvision 관련 라이브러리 import\n",
        "\n",
        "from torchvision import utils\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5uikNndWW_9T"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0. 데이터셋 로드"
      ],
      "metadata": {
        "id": "0GitHpa7XBmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8x8E-xwbW_Qt",
        "outputId": "4cc3f160-d02e-48b2-dc0f-bf0eda01b366"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YmBD1wKovqoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jsonlines\n",
        "!pip install pdf2image"
      ],
      "metadata": {
        "id": "u3gRUgpEW9cq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46ad5f4c-c7b8-443a-f311-1f32f341f39d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading jsonlines-3.0.0-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from jsonlines) (21.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonlines) (4.2.0)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-3.0.0\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.16.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from pdf2image) (7.1.2)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "import tensorflow as tf\n",
        "import keras\n"
      ],
      "metadata": {
        "id": "0wgRUMyyW9je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import Dataset\n",
        "import glob\n",
        "from PIL import Image\n",
        "import jsonlines\n",
        "import os\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "XW5zuXp1W9nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "class PaperDataSet(Dataset):\n",
        "    def __init__(self, overall_image_path, transform=None):\n",
        "        print(\"initialize data sets\")\n",
        "        self.transform = transform\n",
        "        rating_dict = {}\n",
        "        self.image_list = list()\n",
        "        self.score_list = list()\n",
        "        years = [\"2021\"]\n",
        "        for year in years:\n",
        "            cnt = 0\n",
        "            year_image_path = overall_image_path+\"iclr\"+year+\"/\" #__test__/\n",
        "\n",
        "            with jsonlines.open(f\"{overall_image_path}/iclr{year}_metadata.jsonl\") as read_file:\n",
        "                for line in read_file.iter():\n",
        "                    rating_dict[line['forum']] = line['rating']\n",
        "            input_paths = os.listdir(year_image_path)\n",
        "            for one_file_image_path in tqdm(input_paths, desc=\"make data set\"):\n",
        "                image_path = year_image_path + one_file_image_path + \"/\"\n",
        "                before_add_size = len(self.image_list)\n",
        "                self.image_list.extend(glob.glob(image_path + \"*.jpg\")) # glob: 폴더 내의 파일 찾아줌\n",
        "                rating = rating_dict[one_file_image_path]\n",
        "                self.score_list.extend([rating] * (len(self.image_list)-before_add_size))\n",
        "                cnt += len(self.image_list)-before_add_size\n",
        "            print(f\"{year}: {cnt}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_list[idx]\n",
        "        label = self.score_list[idx]\n",
        "        img = Image.open(image_path)\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label"
      ],
      "metadata": {
        "id": "xw36Jb0yW9s-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"drive/Shareddrives/소종-논문/\" \n",
        "dataset_file_name = 'iclr2021_dataset.pt'"
      ],
      "metadata": {
        "id": "cSfWpocEW9xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_save_data_set(image_path, dataset_file_name):\n",
        "  print(\"start to make data set\")\n",
        "  transform = transforms.Compose([\n",
        "      transforms.Resize((224, 224)),\n",
        "      transforms.ToTensor(),\n",
        "  ])\n",
        "\n",
        "  dataset = PaperDataSet(image_path, transform=transform)\n",
        "  print(f\"data set length: {dataset.__len__()}\")\n",
        "\n",
        "  torch.save(dataset, dataset_file_name)\n",
        "  print(\"save data sets\")"
      ],
      "metadata": {
        "id": "cgKR9l_DXcJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_save_data_set(image_path, dataset_file_name)\n",
        "# data_set_usage_ex(dataset_file_name)"
      ],
      "metadata": {
        "id": "Lt1_lnn8XcMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xEqyEffNZy6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "\n",
        "dataset = torch.load(dataset_file_name)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "print(\"train size:\", train_size)\n",
        "\n",
        "test_size = len(dataset) - train_size\n",
        "print(\"test size:\", test_size)\n",
        "# validation \n",
        "train_dataset, test_dataset = random_split(dataset, [train_size,test_size])\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=50, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "7WjyhkPoaxNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "02 training¶"
      ],
      "metadata": {
        "id": "Bvjr_4qUNeYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 학습 환경 설정\n",
        "\n",
        "resnet50 = models.resnet50(pretrained=False).to(device) # true 옵션으로 사전 학습된 모델을 로드\n",
        "\n",
        "# transfer learning 사용 시 추가 \n",
        "# if using_transfer_learning:\n",
        "#   for param in resnet50.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "model = nn.Sequential(\n",
        "    resnet50,\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(1000, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 1)\n",
        ").to(device)\n"
      ],
      "metadata": {
        "id": "_UegSgy0NMSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "lr = 0.0001\n",
        "num_epochs = 10\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "loss_function = nn.MSELoss().to(device)"
      ],
      "metadata": {
        "id": "KaZHNA_HNk7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'num_epochs':num_epochs,\n",
        "    'optimizer':optimizer,\n",
        "    'loss_function':loss_function,\n",
        "    'train_dataloader':train_dataloader,\n",
        "    'test_dataloader': test_dataloader,\n",
        "    'device':device\n",
        "}"
      ],
      "metadata": {
        "id": "9CHLTVscNqcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "3HgavN8RgIgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "from numpy import vstack\n",
        "\n",
        "def train(model, params):\n",
        "    total_start = time.time()\n",
        "    loss_function=params[\"loss_function\"]\n",
        "    train_dataloader=params[\"train_dataloader\"]\n",
        "    test_dataloader=params[\"test_dataloader\"]\n",
        "    device=params[\"device\"]\n",
        "\n",
        "    print(\"start train\")\n",
        "    print(\"train size:\", train_size)\n",
        "    print(\"test size:\", test_size)\n",
        "    for epoch in range(0, num_epochs):\n",
        "      epoch_start = time.time()\n",
        "      trained_number = 0\n",
        "      for i, data in enumerate(train_dataloader, 0):\n",
        "        # train dataloader 로 불러온 데이터에서 이미지와 라벨을 분리\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.type(torch.LongTensor) \n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # 이전 batch에서 계산된 가중치를 초기화\n",
        "        optimizer.zero_grad() \n",
        "        # forward + back propagation 연산\n",
        "        outputs = model(inputs).squeeze()\n",
        "        train_loss = loss_function(outputs.to(torch.float32), labels.to(torch.float32))\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "        trained_number += labels.size(0)\n",
        "        \n",
        "        if i%100==0:\n",
        "          print(f\"epoch {epoch+1} {trained_number/train_size*100}% train finish\")\n",
        "      print(f\"epoch {epoch+1} train finish\") \n",
        "      # test accuracy 계산\n",
        "      total = 0\n",
        "      correct = 0\n",
        "      loss = 0\n",
        "\n",
        "      for i, data in enumerate(test_dataloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.type(torch.LongTensor) \n",
        "        labels = labels.to(device)\n",
        "        \n",
        "\n",
        "        # 결과값 연산\n",
        "        outputs = model(inputs).squeeze()\n",
        "        i_batch_size = labels.size(0)\n",
        "        total += i_batch_size\n",
        "        correct += (abs(outputs - labels)<0.5).sum().item() # 변경될 수 있음 \n",
        "        test_loss = loss_function(outputs.to(torch.float32), labels.to(torch.float32)).item()\n",
        "        loss += i_batch_size * test_loss\n",
        "        if i%50==0:\n",
        "          print(f\"epoch {epoch+1} {total/test_size*100}% test finish\")\n",
        "\n",
        "      # 학습 결과 출력\n",
        "      print('Epoch: %d/%d, Train loss: %.6f, Test loss: %.6f, Accuracy: %.2f' %(epoch+1, num_epochs, train_loss.item(), loss/total, 100*correct/total))\n",
        "\n",
        "      epoch_elapsed_time = time.time() - epoch_start\n",
        "      epoch_elapsed_time_list = str(datetime.timedelta(seconds=epoch_elapsed_time)).split(\".\")\n",
        "      total_elapsed_time = time.time() - total_start\n",
        "      total_elapsed_time_list = str(datetime.timedelta(seconds=total_elapsed_time)).split(\".\")\n",
        "      print(f\"Epoch {epoch+1} Elapsed time is {epoch_elapsed_time_list[0]}\")  \n",
        "      print(f\"Total Elapsed time is {total_elapsed_time_list[0]}\")  "
      ],
      "metadata": {
        "id": "W2ZnqIjCNqfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "train(model, params)"
      ],
      "metadata": {
        "id": "cmAGMDr2Nqhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0zxw_uyDk52_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}